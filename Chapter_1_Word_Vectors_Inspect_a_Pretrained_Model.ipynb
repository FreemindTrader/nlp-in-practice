{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FreemindTrader/nlp-in-practice/blob/master/Chapter_1_Word_Vectors_Inspect_a_Pretrained_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaYi3AMUTI9P"
      },
      "source": [
        "# Introduction\n",
        "------------------------\n",
        "In this notebook we'll play around with a pre-trained word model to look at its vocabulary and to try out some of the basic operations commonly performed on word vectors.\n",
        "\n",
        "We'll start by using the Python package `gensim` which implements all of the basic features we need like loading the model, accessing its vocabulary, and performing similarity lookups. Immediately after, though, we'll go \"under the covers\" and perform the same operations manually so you can see what's really going on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGJRiznRTI9S"
      },
      "source": [
        "\n",
        "# Inspecting the Model <a name=\"inspect_model\"></a>\n",
        "-------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTfuotWgVTy4"
      },
      "source": [
        "\n",
        "Along with the original word2vec papers, the authors [released](https://code.google.com/archive/p/word2vec/ \"Homepage for Google's Word2Vec code and pre-trained models\") a large Word2Vec model that they trained on roughly 100 billion words from a Google News dataset. It contains exactly 3 million words, and the word vectors have 300 features each. There are newer, presumably better, pre-trained models, but this is the original.\n",
        "\n",
        "This cell will download the model file and save it to the Colab instance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMl5gBz_9bfQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "628b1a76-7ed4-4828-9d2d-1dc1bb28463b"
      },
      "source": [
        "import gdown\n",
        "\n",
        "print('Downloading original word2vec model...')\n",
        "\n",
        "# Specify the name to give the file locally.\n",
        "output = './GoogleNews-vectors-negative300.bin.gz'\n",
        "\n",
        "# Specify the Google Drive ID of the file.\n",
        "file_id = '0B7XkCwpI5KDYNlNUTTlSS21pQmM'\n",
        "\n",
        "# Download the file.\n",
        "gdown.download('https://drive.google.com/uc?id=' + file_id, output,\n",
        "                quiet=False)\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading original word2vec model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:07, 207MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64u41nmrW9aD"
      },
      "source": [
        "The model is compressed, so we'll need to uncompress it. The zipped version is ~1.6GB, and the unzipped version is ~3.4GB, so expect this cell to take a while (it took ~75 seconds for me)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8WNjX7XZiYz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "37339410-5f0b-4fc1-88f1-2ce2d437c837"
      },
      "source": [
        "!gunzip GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: GoogleNews-vectors-negative300.bin already exists; do you wish to overwrite (y or n)? y\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qeivjqk9b7UH"
      },
      "source": [
        "The following settings will eliminate some unhelpful warnings from the remainder of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZiG46rdb2tg"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doMeLySAVWtg"
      },
      "source": [
        "We'll use a helper function from `gensim` to load it as a `KeyedVector` class that provides a lot of convenience functions. This is a large model to load into memory, so expect this to take a while as well (this cell took ~75 seconds to run for me)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYdHoeeLTI9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ea4808f-a1b8-446b-ec53-e940e1114ff5"
      },
      "source": [
        "import gensim\n",
        "\n",
        "filepath = './GoogleNews-vectors-negative300.bin'\n",
        "\n",
        "print('Loading word2vec model (takes ~75 seconds)...')\n",
        "\n",
        "# Load Google's pre-trained Word2Vec model.\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(filepath,\n",
        "                                                        binary=True,\n",
        "                                                        unicode_errors='ignore')\n",
        "\n",
        "print('  DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading word2vec model (takes ~75 seconds)...\n",
            "  DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMtRwN5tTI9b"
      },
      "source": [
        "## Model Vocabulary<a name=\"model_vocab\"></a>\n",
        "I usually start by poking around the vocabulary of the model to get a feel for it. Let's print some random vocab words in three columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-JkpdjITI9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "804c37e0-242b-4333-b103-ac95ac19f567"
      },
      "source": [
        "import random\n",
        "\n",
        "# Retrieve the list of words in the vocabulary as 'vocab'\n",
        "vocab = list(model.vocab.keys())\n",
        "\n",
        "# Print 20 random words in two columns.\n",
        "for i in range(10):\n",
        "    # Choose and print two random words\n",
        "    print('%30s %30s' % (random.choice(vocab),\n",
        "                         random.choice(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 Mullah_Mateen                         Taiste\n",
            "                    euromicron                       Af_fairs\n",
            "      Lacey_Lamplighters_Lions indefinite-delivery/indefinite-quantity_contract\n",
            "                         ROCCA                William_Novelli\n",
            "                   IMSI_Design               Judge_Drue_Bynum\n",
            "               WrestleMania_XV               CS_Mott_Children\n",
            "                   Jon_Eldreth                      MC_Mulani\n",
            "             Bolot_Sherniyazov                 Pequot_Library\n",
            "                  Charity_Ride                    0_Recommend\n",
            "                      Fund_PPF                       Teamwork\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA1ecG1LTI9j"
      },
      "source": [
        "---\n",
        "Certainly a lot of non-sense in there! I've found this to be fairly typical of pre-trained word models.\n",
        "\n",
        "Let's look more explicitly at some different word types.\n",
        "\n",
        "I'm going to define a little helper function which takes lists of words and then reports which are found, checking both lower and upper case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHn6ditlTI9k"
      },
      "source": [
        "def check_vocab(vocab, try_words):\n",
        "    print(\"%30s    %s\" % ('Word', 'Included'))\n",
        "    print(\"%30s    %s\" % ('====', '========'))\n",
        "\n",
        "    for word in try_words:\n",
        "        print(\"%30s    %s\" % (word, str(word in model.vocab)))\n",
        "        # If the word isn't already lower case, try lower case as well.\n",
        "        if not word.lower() == word:\n",
        "            print(\"%30s    %s\" % (word.lower(), str(word.lower() in model.vocab)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-NGsHibTI9p"
      },
      "source": [
        "**Stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiV5yYIvTI9q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "8bc5e631-8b4d-467e-c94f-ee4c59ebd7d6"
      },
      "source": [
        "check_vocab(vocab, ['a', 'and', 'the'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          Word    Included\n",
            "                          ====    ========\n",
            "                             a    False\n",
            "                           and    False\n",
            "                           the    True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3G_4LdkTI9w"
      },
      "source": [
        "**Multi-word names**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeaySCQETI9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "3d141802-71fd-4fe8-f540-e82d92332df1"
      },
      "source": [
        "check_vocab(vocab, ['Abraham_Lincoln',\n",
        "                    'Michael_Jordan',\n",
        "                    'Tom_Brady',\n",
        "                    'Elon_Musk',\n",
        "                    'United_States',\n",
        "                    'United_States_of_America',\n",
        "                    ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          Word    Included\n",
            "                          ====    ========\n",
            "               Abraham_Lincoln    True\n",
            "               abraham_lincoln    False\n",
            "                Michael_Jordan    False\n",
            "                michael_jordan    True\n",
            "                     Tom_Brady    True\n",
            "                     tom_brady    True\n",
            "                     Elon_Musk    True\n",
            "                     elon_musk    False\n",
            "                 United_States    True\n",
            "                 united_states    False\n",
            "      United_States_of_America    False\n",
            "      united_states_of_america    False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVjOWgaTI91"
      },
      "source": [
        "**Multi-word topics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCKI7YD6TI92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "f9f9c58b-4b90-49bb-9f77-2547b9d9187e"
      },
      "source": [
        "check_vocab(vocab, ['Computer_Science',\n",
        "                    'Global_Warming',\n",
        "                    'Foreign_Policy',\n",
        "                    ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          Word    Included\n",
            "                          ====    ========\n",
            "              Computer_Science    True\n",
            "              computer_science    False\n",
            "                Global_Warming    True\n",
            "                global_warming    True\n",
            "                Foreign_Policy    False\n",
            "                foreign_policy    False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSKDtdYZTI96"
      },
      "source": [
        "**Idioms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko-SFgy6TI97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "af692a0f-0e37-4053-ecf6-88be3554fa43"
      },
      "source": [
        "check_vocab(vocab, ['couch_potato',\n",
        "                    'dime_a_dozen',\n",
        "                    'hit_the_sack',\n",
        "                    'cut_corners',\n",
        "                    ])\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          Word    Included\n",
            "                          ====    ========\n",
            "                  couch_potato    True\n",
            "                  dime_a_dozen    False\n",
            "                  hit_the_sack    False\n",
            "                   cut_corners    False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeBDosDETI9-"
      },
      "source": [
        "**Misspellings** (these are all misspelled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXh8H9jPTI9-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "3e365b44-4aaa-4892-e82a-ec02e32ea5c6"
      },
      "source": [
        "check_vocab(vocab, ['accomodate',\n",
        "                    'begining',\n",
        "                    'concious',\n",
        "                    'incidently',\n",
        "                    'recomendations',\n",
        "                    ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          Word    Included\n",
            "                          ====    ========\n",
            "                    accomodate    True\n",
            "                      begining    True\n",
            "                      concious    True\n",
            "                    incidently    True\n",
            "                recomendations    True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpZk5CMoTI-B"
      },
      "source": [
        "**Punctuation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGWv1YLRTI-B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "aa2df85e-03a7-44cb-b6ec-3b0a69b7bfd1"
      },
      "source": [
        "check_vocab(vocab, ['man`s',\n",
        "                    'man\\'s',\n",
        "                    'it`s',\n",
        "                    'it\\'s',\n",
        "                    'U.S.A.',\n",
        "                    ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          Word    Included\n",
            "                          ====    ========\n",
            "                         man`s    False\n",
            "                         man's    True\n",
            "                          it`s    False\n",
            "                          it's    True\n",
            "                        U.S.A.    True\n",
            "                        u.s.a.    False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oys7SVhZTI-E"
      },
      "source": [
        "**Numbers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0CgAbmTTI-F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "6f8e5d7f-5d14-401c-ff89-c046b1664399"
      },
      "source": [
        "check_vocab(vocab, ['1',\n",
        "                    'one',\n",
        "                    '12',\n",
        "                    'twelve',\n",
        "                    '100',\n",
        "                    'one_hundred',\n",
        "                    ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          Word    Included\n",
            "                          ====    ========\n",
            "                             1    True\n",
            "                           one    True\n",
            "                            12    False\n",
            "                        twelve    True\n",
            "                           100    False\n",
            "                   one_hundred    False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HHFF0U2TI-H"
      },
      "source": [
        "## Sample Vector <a name=\"sample_vector\"></a>\n",
        "\n",
        "Let's take a look inside a single vector, for the word \"couch\".\n",
        "\n",
        "From the output we can see that the values appear to range within -1.0 to 1.0, and that the vector is dense rather than sparse (no features are zero)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9MCTF59TI-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "2304593a-8d88-4c0c-c6b7-27c038671e41"
      },
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Let's peek at the word vector for the word 'couch'.\n",
        "vec = model.word_vec('couch')\n",
        "\n",
        "# Shape and sample values:\n",
        "print(\"Vector shape: \" + str(vec.shape))\n",
        "print(\"Sample values:  <%.4f, %.4f, %.4f, ..., %.4f, %.4f>\" %\n",
        "      (vec[0], vec[1], vec[2], vec[-2], vec[-1]))\n",
        "\n",
        "# What's the vector's magnitude?\n",
        "print(\"Norm: %.2f\" % np.linalg.norm(vec))\n",
        "\n",
        "# Are some values zero? How many?\n",
        "num_zero = len(vec) - np.count_nonzero(vec)\n",
        "print(\"Number of zeros: %d of %d\" % (num_zero, len(vec)))\n",
        "\n",
        "# Plot a histogram of the feature values to visualize their\n",
        "# distribution.\n",
        "ax = sns.distplot(vec, kde=False, rug=True)\n",
        "t = ax.set_title('Histogram of Feature Values')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector shape: (300,)\n",
            "Sample values:  <0.2285, -0.2949, 0.0006, ..., 0.0854, -0.0018>\n",
            "Norm: 3.13\n",
            "Number of zeros: 0 of 300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMYoA_4STI-L"
      },
      "source": [
        "# Word Similarities with gensim <a name=\"word_sim_gensim\"></a>\n",
        "----------------------------------------------\n",
        "`gensim` includes convenience functions for computing a number of common word similarity operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9PlHTXjTI-L"
      },
      "source": [
        "## Compare Two Words<a name=\"compare_two_gensim\"></a>\n",
        "--------------------------------\n",
        "The `model` object has convenience functions for comparing two vectors. The below code shows that \"couch\" and \"book\" have a low similarity, while \"couch\" and \"sofa\" are very similar--as we would hope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE4sgfp6TI-M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5ec5ea73-a79d-4f39-a335-adb65a2fa2ad"
      },
      "source": [
        "# Let's try comparing some specific words.\n",
        "# First, how similar are \"couch\" and \"book\"?\n",
        "score = model.similarity('couch', 'book')\n",
        "print(\"Cosine similarity between 'couch' and 'book' is %.2f\" % score)\n",
        "\n",
        "# How about \"couch\" and \"sofa\"?\n",
        "score = model.similarity('couch', 'sofa')\n",
        "print(\"Cosine similarity between 'couch' and 'sofa' is %.2f\\n\" % score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'couch' and 'book' is 0.12\n",
            "Cosine similarity between 'couch' and 'sofa' is 0.83\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YLa0UefTI-O"
      },
      "source": [
        "## Find Most Similar<a name=\"find_sim_gensim\"></a>\n",
        "----------------------------\n",
        "We can also find the most similar words in the vocabulary to \"couch\".\n",
        "\n",
        "The results look pretty sensible!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-5zDGWjTI-O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "5417d4d5-4279-4b1d-c103-4b5380e39ef8"
      },
      "source": [
        "# What are the 10 most similar words to \"couch\" in the vocabulary?\n",
        "results = model.most_similar(positive='couch', topn=10)\n",
        "\n",
        "# Print out the results.\n",
        "print(\"10 most similar words to 'couch':\")\n",
        "print(\"%20s    %s\" % ('word', 'score'))\n",
        "for (word, score) in results:\n",
        "    print(\"%20s    %.2f\" % (word, score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 most similar words to 'couch':\n",
            "                word    score\n",
            "                sofa    0.83\n",
            "            recliner    0.74\n",
            "             couches    0.70\n",
            "         comfy_couch    0.67\n",
            "               futon    0.65\n",
            "    al_Jabouri_slept    0.62\n",
            "            loveseat    0.62\n",
            "       beanbag_chair    0.62\n",
            "      recliner_chair    0.61\n",
            "              settee    0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aEmSvDBTI-R"
      },
      "source": [
        "Fun side note: What's with the \"al Jabouri slept\" result? I believe this is an artifact of the Google News dataset. This particular phrase comes from [this story](https://www.mercurynews.com/2010/12/29/three-suicide-bombers-used-to-kill-tenacious-iraqi-cop/) which mentions an officer named al-Jabouri sleeping on a couch!\n",
        "A problem with this Google News dataset is that news outlets all over will take articles (from Reuters, I think?) and just modify them slightly, so there are many near-duplicate news articles out there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbrM5f6LTI-R"
      },
      "source": [
        "# Word Similarity from Scratch<a name=\"word_sim_scratch\"></a>\n",
        "--------------------------------------\n",
        "It's great that gensim makes these operations easy for us, but to make sure we have a firm grasp on how they work, let's implement the above vector operations from scratch--just for educational purposes.\n",
        "\n",
        "(Side Note: If you want to keep playing with gensim a little more, there's nice documentation for the KeyedVectors class [here](https://radimrehurek.com/gensim/models/keyedvectors.html)).\n",
        "\n",
        "Let's start by pulling the word vectors matrix out of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfmHcihyTI-R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a71a79d7-4bc7-4765-a3e2-874813cc262e"
      },
      "source": [
        "# Note - Older versions of gensim stored the vectors in `model.syn0`\n",
        "vecs = model.vectors\n",
        "\n",
        "print('Word vector matrix is: ' + str(vecs.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word vector matrix is: (3000000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4o67kSaTI-U"
      },
      "source": [
        "## Word-pair Similarity from Scratch<a name=\"word_pair_scratch\"></a>\n",
        "--------------------------\n",
        "Now let's pull out our specific word vectors manually by looking up their index from the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAQY0Be0TI-U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61480c4f-0c62-4ea6-b549-652ba8f6faff"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Let's look up the index of the vector for 'couch' and 'sofa'.\n",
        "w1 = model.vocab['couch'].index\n",
        "w2 = model.vocab['sofa'].index\n",
        "\n",
        "# Select the vectors using their row index.\n",
        "v1 = vecs[w1, :]\n",
        "v2 = vecs[w2, :]\n",
        "\n",
        "# Let's check out the norms of these two vectors.\n",
        "print('Norm for \"couch\": %.2f' % np.linalg.norm(v1))\n",
        "print('Norm for \"sofa\": %.2f' % np.linalg.norm(v2))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Norm for \"couch\": 3.13\n",
            "Norm for \"sofa\": 3.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D--4lRk1TI-Y"
      },
      "source": [
        "----------------\n",
        "Here's the formula for the cosine similarity of two vectors 'x' and 'y'.\n",
        "\n",
        "$ cos(\\pmb x, \\pmb y) = \\frac {\\pmb x \\cdot \\pmb y}{||\\pmb x|| \\cdot ||\\pmb y||} $\n",
        "\n",
        "The formula is written as the dot-product of the vectors, divided by the product of their magnitudes. However, we can change the order and normalize the vectors first, then take their dot products. It's better to think of it in this order--we'll see why in a bit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPK1rxugTI-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "c9c101f3-641c-4284-ebce-a40e39a256b7"
      },
      "source": [
        "# Normalize our vectors:\n",
        "v1_norm = v1 / np.linalg.norm(v1)\n",
        "v2_norm = v2 / np.linalg.norm(v2)\n",
        "\n",
        "# Let's double check the result:\n",
        "print('New norm of \"couch\": %.2f' % np.linalg.norm(v1_norm))\n",
        "print('New norm of \"sofa\": %.2f' % np.linalg.norm(v2_norm))\n",
        "\n",
        "# Now we can take the dot-product of the normalized vectors:\n",
        "cos_sim = np.dot(v1_norm, v2_norm)\n",
        "\n",
        "print('\\nCosine similarity between \"couch\" and \"sofa\": %.2f' % cos_sim)\n",
        "\n",
        "# Also show the gensim results as a sanity-check\n",
        "print('    (gensim: %.2f)' % model.similarity('couch', 'sofa'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New norm of \"couch\": 1.00\n",
            "New norm of \"sofa\": 1.00\n",
            "\n",
            "Cosine similarity between \"couch\" and \"sofa\": 0.83\n",
            "    (gensim: 0.83)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXaXLoQzTI-b"
      },
      "source": [
        "## Word Similarity Search from Scratch<a name=\"word_search_scratch\"></a>\n",
        "----------------------------\n",
        "Now let's try searching the vocabulary for the top-10 most similar words to \"couch\".\n",
        "\n",
        "We could iterate over all 3M words in the vocabulary, calculating the cosine similarity as we did above, and then sorting them. This is brutally slow, though! As you may know, it's much more efficient to perform vector-matrix operations. We'll multiply the vector against the whole matrix, and the processor will be able to use efficient linear algebra routines and SIMD instructions to speed up this heavy compute task.\n",
        "\n",
        "Here is where it's going to help us to change up the order of operations. If we simply normalize the entire word vector matrix as pre-processing step, then we never have to worry about the normalization step again!\n",
        "\n",
        "We start by calculating the norms for all 3M vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWUopMkcTI-b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "54b06461-5837-47a9-b436-69402675fa44"
      },
      "source": [
        "%%time\n",
        "\n",
        "print(\"Calculating vector norms, this can be slow...\\n\")\n",
        "\n",
        "# First, numpy can calculate the norms of all of our vectors.\n",
        "# We specify that we want the norms calculated along the first axis,\n",
        "# since these are row vectors.\n",
        "norms = np.linalg.norm(vecs, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating vector norms, this can be slow...\n",
            "\n",
            "CPU times: user 1.39 s, sys: 7.49 ms, total: 1.4 s\n",
            "Wall time: 1.41 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2h1fzXmTI-d"
      },
      "source": [
        "---------\n",
        "Now we divide the vectors by their norms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-rqUspQTI-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a0f26bc4-4932-4ad0-a9ce-ad8d95e6da9a"
      },
      "source": [
        "%%time\n",
        "\n",
        "print(\"Shape of vecs: \" + str(vecs.shape))\n",
        "print(\"Shape of norms: \" + str(norms.shape))\n",
        "\n",
        "# Add a second dimension to norms, so that it's 3M x 1.\n",
        "norms = norms.reshape(len(norms), 1)\n",
        "\n",
        "print(\"\\nNormalizing all vectors, this can be slow...\")\n",
        "\n",
        "# Vecs is [3M x 300] and norms is [3M x 1]. Performing division\n",
        "# will result in each row of 'vecs' being divided by the scalar\n",
        "# in the corresponding row of 'norms'.\n",
        "vecs_norm = vecs / norms\n",
        "\n",
        "# Sanity check...\n",
        "print(\"\\nNew norm of first vector: %.2f \\n\" %\n",
        "      (np.linalg.norm(vecs_norm[0, :])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of vecs: (3000000, 300)\n",
            "Shape of norms: (3000000,)\n",
            "\n",
            "Normalizing all vectors, this can be slow...\n",
            "\n",
            "New norm of first vector: 1.00 \n",
            "\n",
            "CPU times: user 1.06 s, sys: 0 ns, total: 1.06 s\n",
            "Wall time: 1.06 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrcjzNaVTI-f"
      },
      "source": [
        "-------------\n",
        "Now that we have the normalized vectors, we can calculate the cosine similarities for 'couch' and all 3M vocabulary words!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "329xgwSBTI-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "76f42ff9-0600-4413-814c-cef3b8adb793"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Look up the index of the vector for 'couch'.\n",
        "w_i = model.vocab['couch'].index\n",
        "\n",
        "# Select the *normalized* vector using the row index.\n",
        "v_norm = vecs_norm[w_i, :]\n",
        "\n",
        "# For our matrix-vector multiplication, we need v_norm\n",
        "# as [300 x 1]\n",
        "v_norm = v_norm.reshape(len(v_norm), 1)\n",
        "\n",
        "print('Calculating all word similarities...\\n')\n",
        "\n",
        "# Perform the matrix-vector multiplication.\n",
        "#   vecs_norm   *   v_norm     =  all_sims\n",
        "#   [3M x 300]  *   [300 x 1]  =  [3M x 1]\n",
        "all_sims = vecs_norm.dot(v_norm)\n",
        "\n",
        "# Remove the extra dimension from the similarity values.\n",
        "all_sims = all_sims.flatten()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating all word similarities...\n",
            "\n",
            "CPU times: user 612 ms, sys: 9.66 ms, total: 622 ms\n",
            "Wall time: 326 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYHwwZzjTI-i"
      },
      "source": [
        "----------\n",
        "The final step is simply to sort the results and display them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Y29YlT8KTI-i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "d9e46dfd-a9c3-4dd4-a95b-dfe6b62a66e3"
      },
      "source": [
        "%%time\n",
        "\n",
        "# The gensim class contains a list of all words in the vocabulary.\n",
        "# We'll need this list in order to map back from row indeces to\n",
        "# their words.\n",
        "vocab_words = model.index2word\n",
        "\n",
        "# Turn the similarities vector into a list of tuples in the form\n",
        "#   (index, similarity)\n",
        "# e.g.,\n",
        "#  [(0, 0.03), (1, 0.20), (2, 0.08), ...]\n",
        "results = enumerate(all_sims)\n",
        "\n",
        "print(\"Sorting similarities...\\n\")\n",
        "\n",
        "# Now sort the list of tuples by the similarity value.\n",
        "# Sort descending, with highest similarity first.\n",
        "results = sorted(results, key=lambda x:x[1], reverse=True)\n",
        "\n",
        "print(\"Top 10 most similar words to 'couch':\")\n",
        "\n",
        "# Display the top 10 results and their similarity.\n",
        "for i in range(10):\n",
        "    # Get the word index for result 'i'.\n",
        "    word_index = results[i][0]\n",
        "\n",
        "    # Lookup the word.\n",
        "    word = vocab_words[word_index]\n",
        "\n",
        "    # Print the word and its similarity value.\n",
        "    print('%20s   %.2f' % (word, results[i][1]))\n",
        "\n",
        "print('')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sorting similarities...\n",
            "\n",
            "Top 10 most similar words to 'couch':\n",
            "               couch   1.00\n",
            "                sofa   0.83\n",
            "            recliner   0.74\n",
            "             couches   0.70\n",
            "         comfy_couch   0.67\n",
            "               futon   0.65\n",
            "    al_Jabouri_slept   0.62\n",
            "            loveseat   0.62\n",
            "       beanbag_chair   0.62\n",
            "      recliner_chair   0.61\n",
            "\n",
            "CPU times: user 4.63 s, sys: 440 ms, total: 5.07 s\n",
            "Wall time: 5.02 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o21okVFVTI-k"
      },
      "source": [
        "---------\n",
        "A small misconception around cosine similarity is that it is always positive, but this is not the case for vectors which contain negative feature values (such as word vectors). The cosine of 180 degrees is -1, so two vectors pointing in opposite directions will have cosine similarity -1.\n",
        "\n",
        "Just for fun, what does the model think are the *least* similar words to \"couch\"?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCY-d-JvTI-l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "88559144-0424-4b83-ff3d-bea4bd3e87aa"
      },
      "source": [
        "print(\"Top 10 least similar words to 'couch':\")\n",
        "\n",
        "# Display the last 10 results and their similarity values.\n",
        "# (Python let's us iterate backwards through a list with\n",
        "# negative indeces).\n",
        "for i in range(-1, -11, -1):\n",
        "    # Get the word index for result 'i'.\n",
        "    word_index = results[i][0]\n",
        "\n",
        "    # Lookup the word.\n",
        "    word = vocab_words[word_index]\n",
        "\n",
        "    # Print the word and its similarity value.\n",
        "    print('%20s   %.2f' % (word, results[i][1]))\n",
        "\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 least similar words to 'couch':\n",
            "    T.Stewart_##-###   -0.28\n",
            "         de_Securite   -0.27\n",
            "        Nasdaq_AKZOY   -0.27\n",
            "        Butch_Alinea   -0.26\n",
            "Asset_Management_NGAM   -0.26\n",
            "               etwcf   -0.25\n",
            "         Stanis_³_aw   -0.25\n",
            "         Algiers_AAI   -0.25\n",
            "     K.Kahne_###-###   -0.24\n",
            "Basmati_Growers_Association   -0.24\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRmk-IyiTI-n"
      },
      "source": [
        "I don't know about you, but when I think about the opposite of \"couch\" the first thing that comes to mind is definitely the *Basmati Growers Association*! :)\n",
        "\n",
        "----------\n",
        "\n",
        "Another \"just for fun\" exercise, here's a faster way to sort the results.\n",
        "Numpy's `argsort` function returns just the sorted indeces, which is enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LFeKZK3TI-o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "c2c0d032-eaeb-40e4-fde9-4f5ff381551f"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Sort the similarities but return the sorted *indeces*.\n",
        "results2 = np.argsort(all_sims, axis=0)\n",
        "\n",
        "# For the top 10 results...\n",
        "for i in range(-2, -12, -1):\n",
        "    # Get the word index for result 'i' (in reverse order).\n",
        "    word_index = results2[i]\n",
        "\n",
        "    # Lookup the word.\n",
        "    word = vocab_words[word_index]\n",
        "\n",
        "    # Lookup the calculated similarity value.\n",
        "    sim = all_sims[word_index]\n",
        "\n",
        "    # Print the word and its similarity value.\n",
        "    print('%20s   %.2f' % (word, sim))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                sofa   0.83\n",
            "            recliner   0.74\n",
            "             couches   0.70\n",
            "         comfy_couch   0.67\n",
            "               futon   0.65\n",
            "    al_Jabouri_slept   0.62\n",
            "            loveseat   0.62\n",
            "       beanbag_chair   0.62\n",
            "      recliner_chair   0.61\n",
            "              settee   0.61\n",
            "CPU times: user 534 ms, sys: 0 ns, total: 534 ms\n",
            "Wall time: 535 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}